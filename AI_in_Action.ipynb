{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KJCK8_KUqbzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install require packages.\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP4pHSsOjy40",
        "outputId": "437b8c72-e91e-494c-d98b-9cad61572c2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/810.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/810.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m809.0/810.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.2\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CDMjcvWOdafc"
      },
      "outputs": [],
      "source": [
        "#step 1\n",
        "#Get your API keys from Openai, you will need to create an account.\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "#don't share your API key with anyone."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read pdf file from source.\n",
        "#note : we can use different loaders for different files.for example to load HTML file we cna use web loader, loading multiple files form one folder we cna use directory loader.\n",
        "from PyPDF2 import PdfReader\n",
        "pdf_reader = PdfReader(\"/content/drive/MyDrive/Colab Notebooks/International-Graduate-Students-Canada-11.12.21-YFR.pdf\")\n",
        "\n"
      ],
      "metadata": {
        "id": "s69_H2rDeNs_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJH7g6QsqNm6",
        "outputId": "03f0403d-068e-4af8-fd7f-88b8f6af2e52"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 2\n",
        "# reading data from our pdf and combining all the data on different pages into one variable.\n",
        "text = ''\n",
        "for i, page in enumerate(pdf_reader.pages):\n",
        "  text = page.extract_text()\n",
        "  if text:\n",
        "    text += text\n",
        "\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "SMBcIWZki7t1",
        "outputId": "add870cc-e69d-4cea-aaef-3d25dcce767e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'REVISED 11/15/2021 2  complete the above NUworks reflection requirements through COP6945. Students who started their program prior to Fall 2021 may have the option to enroll in a 3-credit or 4-credit elective course, COP6940 Personal and Career Development. This course can take the place of a required program elective and a student enrolled in this course would not be required to complete the reflection component in NUworks. *Meet with your Academic Advisor to ensure that you have room in your course map for this option.*  ¨ I have academic program requirements to complete upon returning from co-op.   C) Search for and Apply to Positions:  ¨ Review CPS Academic Calendar and Deadlines for Co-Op Start Dates (Co-op is approved is on a PER ACADEMIC TERM BASIS). Be sure that the dates of the co-op are aligned with the academic calendar and will keep you in status for the duration of the academic term that you will be engaging in experiential learning. ¨ Attend a Job Search Strategies Workshop.  ¨ Keep in mind co-op positions are generally posted four months earlier than the start date  ¨ Search for positions on NUworks Database (successful completion of INT6200 is required for access)  ¨ Search for positions through outside sources (example: LinkedIn, Indeed.com, etc.)  ¨ Be informed and conduct due diligence to ensure that your intended co-op employer/organization and the practical training that you will engage in are valid. Only apply to Co-ops that are academically integral to your program of study and learning objectives – your Co-op Advisor will give guidance and final approval*   D) Once you have received an Offer Letter:  ¨ Review your offer letter and make sure the start and end dates align with your academic calendar ¨ Upload your Co-op Work Permit and offer letter on NUWorks Date sent: __________ ¨ Email a copy of the offer letter to your Co-op Advisor  ¨ Wait for approval. Do not work prior to or beyond Co-op authorized dates ¨ Co-op work cannot be approved for greater than six months per academic program ¨ Without your co-op work permit, you cannot work during your scheduled co-op work term in any capacity – on/off-campus, full/part-time, paid/unpaid – for co-op credit  ¨ You must be registered in an official co-op course (consult with your co-op advisor) ¨ Your co-op position must be full time (30 - 40 hours per week) ¨ Summer co-op positions must meet the requirements above, if you choose to work full time on your study permit in the summer, the position will not be considered as co-op work, and you must return to complete at least one course.  Questions?    Contact Your Academic Advisor For  Questions Regarding:  Contact Your Co-op Advisor for  Questions Regarding:  Course Planning and Mapping  Experiential Learning, Search Strategies, and Career Readiness Programing  Academic Eligibility/INT62000 Experiential Learning Prep Course  NUworks Database Registration and Use  Aligning Co-Op placement dates with your graduation date  Co-Op Start Date Deadlines   Co-op Approval  Find your Academic Advisor Here   Find your Co-op/Experiential Advisor Here or visit our website for our Walk-In schedule.     For questions related to your Co-op Work Permit application or other Canadian immigration questions related to working in Canada, please contact your International Student Advisor, or see the OGS Canada website: https:// international.northeastern.edu/ogs/student-support/global-campuses/canada/working-while-studying/ REVISED 11/15/2021 2  complete the above NUworks reflection requirements through COP6945. Students who started their program prior to Fall 2021 may have the option to enroll in a 3-credit or 4-credit elective course, COP6940 Personal and Career Development. This course can take the place of a required program elective and a student enrolled in this course would not be required to complete the reflection component in NUworks. *Meet with your Academic Advisor to ensure that you have room in your course map for this option.*  ¨ I have academic program requirements to complete upon returning from co-op.   C) Search for and Apply to Positions:  ¨ Review CPS Academic Calendar and Deadlines for Co-Op Start Dates (Co-op is approved is on a PER ACADEMIC TERM BASIS). Be sure that the dates of the co-op are aligned with the academic calendar and will keep you in status for the duration of the academic term that you will be engaging in experiential learning. ¨ Attend a Job Search Strategies Workshop.  ¨ Keep in mind co-op positions are generally posted four months earlier than the start date  ¨ Search for positions on NUworks Database (successful completion of INT6200 is required for access)  ¨ Search for positions through outside sources (example: LinkedIn, Indeed.com, etc.)  ¨ Be informed and conduct due diligence to ensure that your intended co-op employer/organization and the practical training that you will engage in are valid. Only apply to Co-ops that are academically integral to your program of study and learning objectives – your Co-op Advisor will give guidance and final approval*   D) Once you have received an Offer Letter:  ¨ Review your offer letter and make sure the start and end dates align with your academic calendar ¨ Upload your Co-op Work Permit and offer letter on NUWorks Date sent: __________ ¨ Email a copy of the offer letter to your Co-op Advisor  ¨ Wait for approval. Do not work prior to or beyond Co-op authorized dates ¨ Co-op work cannot be approved for greater than six months per academic program ¨ Without your co-op work permit, you cannot work during your scheduled co-op work term in any capacity – on/off-campus, full/part-time, paid/unpaid – for co-op credit  ¨ You must be registered in an official co-op course (consult with your co-op advisor) ¨ Your co-op position must be full time (30 - 40 hours per week) ¨ Summer co-op positions must meet the requirements above, if you choose to work full time on your study permit in the summer, the position will not be considered as co-op work, and you must return to complete at least one course.  Questions?    Contact Your Academic Advisor For  Questions Regarding:  Contact Your Co-op Advisor for  Questions Regarding:  Course Planning and Mapping  Experiential Learning, Search Strategies, and Career Readiness Programing  Academic Eligibility/INT62000 Experiential Learning Prep Course  NUworks Database Registration and Use  Aligning Co-Op placement dates with your graduation date  Co-Op Start Date Deadlines   Co-op Approval  Find your Academic Advisor Here   Find your Co-op/Experiential Advisor Here or visit our website for our Walk-In schedule.     For questions related to your Co-op Work Permit application or other Canadian immigration questions related to working in Canada, please contact your International Student Advisor, or see the OGS Canada website: https:// international.northeastern.edu/ogs/student-support/global-campuses/canada/working-while-studying/ '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 3\n",
        "#This code splits a piece of text into smaller chunks to enable easier processing,\n",
        "#with each chunk containing up to 500 characters and overlapping by 100 characters.\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "chuncks=[]\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "chunk_size = 500,\n",
        "chunk_overlap  = 100,\n",
        "length_function = len,\n",
        ")\n",
        "chuncks = text_splitter.split_text(text)\n",
        "\n",
        "print(\"total Chuncks created\",len(chuncks))\n",
        "print(\"sample chunck\",chuncks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu4EvgBVjR5E",
        "outputId": "c543bedb-427d-4b49-8e2f-c92da83f57be"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total Chuncks created 18\n",
            "sample chunck REVISED 11/15/2021 2  complete the above NUworks reflection requirements through COP6945. Students who started their program prior to Fall 2021 may have the option to enroll in a 3-credit or 4-credit elective course, COP6940 Personal and Career Development. This course can take the place of a required program elective and a student enrolled in this course would not be required to complete the reflection component in NUworks. *Meet with your Academic Advisor to ensure that you have room in your\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 4\n",
        "#This code utilizes machine learning techniques to convert the text chunks into numerical vectors, allowing for easier comparison and analysis.\n",
        "#The \"FAISS\" library efficiently stores these vectors, enabling fast searching and retrieval of relevant information within the text data.\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "\n",
        "#converting chunks into vector\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "#convert text to numeric vector\n",
        "#for example 'book' --> '8493'\n",
        "docsearch = FAISS.from_texts(chuncks, embeddings)\n",
        "\n"
      ],
      "metadata": {
        "id": "OInjZ2B1lOY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cab1ccc-ec5f-419b-86df-179d2a83a654"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading Question answer chain\n",
        "# in this code we are creating a chain combining chunks with our query by stuffing( merging  our query with previously created chunk)\n",
        "\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# add description here.(combine multiple chuncks which is relevant to the query )\n",
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2HYYS9HEouIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd675b01-0aac-4e14-cd91-ddb7b1e65b03"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#questining the PDF\n",
        "\n",
        "\n",
        "#@title Northeastern AI workshop\n",
        "query='what is this pdf about ?' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#generating prompt from our query\n",
        "def generate_prompt(query):\n",
        "    prompt = f\" you are  a student advisor of a Northeastern university and answer the following query:{query}\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "prompt = generate_prompt(query)\n",
        "\n",
        "#searching similar docs.\n",
        "docs = docsearch.similarity_search(query)\n",
        "\n",
        "#running query.\n",
        "#make it more understandable.(we combine most relevant search results with our prompt to generate answer.)\n",
        "answer=chain.run(input_documents=docs, question=prompt)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peYju2CJyhCY",
        "outputId": "a55bda7e-a659-4655-8f62-1eb9eba4601f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The PDF contains information and guidelines for students participating in co-op programs at Northeastern University. It covers topics such as the co-op work permit process, academic eligibility, registration and use of the NUworks database, aligning co-op placement dates with graduation dates, and contact information for academic and co-op advisors. It also emphasizes the importance of only applying for co-ops that align with the student's academic program and learning objectives. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5pEK8SBG5MQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1pj_HcQVqgg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SbRTwsFegl6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj218Y33gqXv",
        "outputId": "c43ef83d-d4c2-43b5-e4a6-e87a21e0e378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.106.15.177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ipvYSPXhNHN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}